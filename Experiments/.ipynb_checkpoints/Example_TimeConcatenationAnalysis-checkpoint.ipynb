{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "institutional-document",
   "metadata": {},
   "source": [
    "## Time concatenation analysis: demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "superior-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import mne\n",
    "from mne.decoding import SPoC\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "import pickle \n",
    "import sys\n",
    "# from Utilities folder\n",
    "sys.path.insert(1, './Utilities/icn_m1')\n",
    "import os\n",
    "sys.path.insert(1, './Utilities/')\n",
    "from FilterBank import FilterBank\n",
    "from ML_models import get_model\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flying-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define settings\n",
    "# change them accordinly\n",
    "settings = {}\n",
    "settings['data_path'] = \"C:/Users/Pilin/Dropbox (Brain Modulation Lab)/Experiments/CRCNS/Data/Epoched/\"\n",
    "settings['num_patients'] = ['000'] # for this example we only use one subject\n",
    "# subfolders indicates the session in this dataset\n",
    "settings['subfolders']=[['ses-right']]  # this subject only has one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "def append_time_dim(arr, y_, time_stamps):\n",
    "    \"\"\"\n",
    "    apply added time dimension for the data array and label given time_stamps (with downsample_rate=100) in 100ms / need to check with 1375Hz\n",
    "    @author: Timon Merk\n",
    "    \"\"\"\n",
    "    time_arr = np.zeros([arr.shape[0]-time_stamps, int(time_stamps*arr.shape[1])])\n",
    "    for time_idx, time_ in enumerate(np.arange(time_stamps, arr.shape[0])):\n",
    "        for time_point in range(time_stamps):\n",
    "            time_arr[time_idx, time_point*arr.shape[1]:(time_point+1)*arr.shape[1]] = arr[time_-time_point,:]\n",
    "    return time_arr, y_[time_stamps:]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basic-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some experiments and model parameters\n",
    "laterality = [\"CON\", \"IPS\"]\n",
    "signal = [\"STN\", \"ECOG\"]\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=False)\n",
    "spoc = SPoC(n_components=1, log=True, reg='oas', transform_into ='average_power', rank='full')\n",
    "USED_MODEL = 3 # 3 == GLM with alpha 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-wagner",
   "metadata": {},
   "source": [
    "### Load the data from both modalities.\n",
    "This data was already pre-processed, following these steps:\n",
    "1. Epochs of 100 ms were extracted.\n",
    "2. Band-passed filtered epoched data at 8 frequency bands ([4, 8], [8, 12], [13, 20], [20, 35], [13, 35], [60, 80], [90, 200], [60, 200])\n",
    "3. The target variable was downsampled accordinly to the 100 ms epoch lenght.\n",
    "\n",
    "If you want to run this code with your own data, please be sure of arranging your data in a 4d array as follows:\n",
    "(epochs, channels, samples, frequency bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legendary-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "s = 0 # when working with all subjects, this is a for\n",
    "subfolders=settings[\"subfolders\"][s]\n",
    "ss = 0 # when working with all subjects, this is a for, since there are subjects which have more than one session.\n",
    "X_ECOG = [] # to append data\n",
    "X_STN =[] \n",
    "Y_con = []\n",
    "Y_ips = []\n",
    "list_of_files_ecog = os.listdir(settings['data_path']+'ECOG') # list of files in the current directory\n",
    "list_of_files_stn = os.listdir(settings['data_path']+'STN') \n",
    "\n",
    "file_name_ = 'ECOG_epochs_sub_' + settings['num_patients'][s] + '_sess_'+subfolders[ss][4:]\n",
    "\n",
    "file_ecog = [each_file for each_file in list_of_files_ecog if each_file.startswith(file_name_)]\n",
    "file_name_='STN_epochs_sub_' + settings['num_patients'][s] + '_sess_'+subfolders[ss][4:]\n",
    "\n",
    "# only load data from runs in which both modali\n",
    "file_stn= [each_file for each_file in list_of_files_stn if each_file.startswith(file_name_)]\n",
    "idx_file = [f for f in file_stn if list(set() & set(file_ecog))]\n",
    "matching_stn = [f for f in file_stn if any(f[4:] in xs for xs in file_ecog)]\n",
    "matching_ecog = [f for f in file_ecog if any(f[4:] in xs for xs in file_stn)]\n",
    "\n",
    "if len(matching_ecog) != len(matching_stn):\n",
    "    raise('Error loading data')\n",
    "\n",
    "for e in range(len(matching_ecog)):\n",
    "    with open(settings['data_path'] +'ECOG/' + matching_ecog[e], 'rb') as handle:\n",
    "        sub_ = pickle.load(handle)    \n",
    "        data = sub_['epochs']\n",
    "        X_ECOG.append(data)\n",
    "        label_ips = sub_['label_ips']\n",
    "        label_con = sub_['label_con']\n",
    "        Y_con.append(label_con)\n",
    "        Y_ips.append(label_ips)\n",
    "    with open(settings['data_path'] +'STN/' + matching_stn[e], 'rb') as handle:\n",
    "        sub_ = pickle.load(handle)\n",
    "        data = sub_['epochs']\n",
    "        X_STN.append(data)           \n",
    "\n",
    "X_ECOG = np.concatenate(X_ECOG, axis=0)\n",
    "X_STN = np.concatenate(X_STN, axis=0)\n",
    "Y_con = np.concatenate(Y_con, axis=0)\n",
    "Y_ips = np.concatenate(Y_ips, axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assured-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the ECoG data is:\n",
      "(epochs, channels, samples, frequency bands):\n",
      "(2810, 6, 1001, 8)\n",
      "The shape of the STN-LFP data is:\n",
      "(epochs, channels, samples, frequency bands):\n",
      "(2810, 3, 1001, 8)\n"
     ]
    }
   ],
   "source": [
    "# print data shape\n",
    "print('The shape of the ECoG data is:\\n(epochs, channels, samples, frequency bands):\\n' + str(X_ECOG.shape))\n",
    "print('The shape of the STN-LFP data is:\\n(epochs, channels, samples, frequency bands):\\n' + str(X_STN.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "victorian-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare saving variable\n",
    "# for the purpose of this example we save some of them, but here you can define as many saving variables as you want to!\n",
    "Ypre_tr = OrderedDict()\n",
    "score_tr = OrderedDict()\n",
    "Ypre_te = OrderedDict()\n",
    "score_te = OrderedDict()\n",
    "Label_tr = OrderedDict()\n",
    "Label_te = OrderedDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-seventh",
   "metadata": {},
   "source": [
    "### Run the experiment!\n",
    "(and be patient, it can take some minutes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNIN SUBJECT_000_SESS_ses-right_SIGNAL_STN\n",
      "time_lag 1\n",
      "training CON\n",
      "training IPS\n",
      "time_lag 2\n",
      "training CON\n",
      "training IPS\n",
      "time_lag 3\n",
      "training CON\n",
      "training IPS\n",
      "time_lag 4\n",
      "training CON\n",
      "training IPS\n",
      "time_lag 5\n",
      "training CON\n",
      "training IPS\n",
      "time_lag 6\n",
      "training CON\n",
      "training IPS\n"
     ]
    }
   ],
   "source": [
    "# run the experiment for every type of signal, time concatenation window and laterality\n",
    "for m, eeg in enumerate(signal): \n",
    "    if eeg == \"ECOG\":\n",
    "        X = X_ECOG\n",
    "    else:\n",
    "        X = X_STN\n",
    "    print('RUNNIN SUBJECT_'+ settings['num_patients'][s]+ '_SESS_'+ str(subfolders[ss]) + '_SIGNAL_' + eeg)\n",
    "    for t in range(1,11):\n",
    "        print(\"time_lag %s\" %t)\n",
    "        for ll, mov in enumerate(laterality):\n",
    "            print(\"training %s\" %mov)\n",
    "            score_tr[mov] = []\n",
    "            score_te[mov] = []\n",
    "            Ypre_tr[mov] = []\n",
    "            Ypre_te[mov] = []\n",
    "            Label_tr[mov] = []\n",
    "            Label_te[mov] = []\n",
    "            Coef[mov] = []\n",
    "            hyperparams[mov] = []\n",
    "            if ll == 0:\n",
    "                label = Y_con\n",
    "            else:\n",
    "                label = Y_ips\n",
    "\n",
    "            features = FilterBank(estimator=spoc)\n",
    "\n",
    "            for train_index, test_index in cv.split(label):\n",
    "                Ztr, Zte = label[train_index], label[test_index]\n",
    "                gtr = features.fit_transform(X[train_index], Ztr)\n",
    "                gte = features.transform(X[test_index])\n",
    "\n",
    "\n",
    "                dat_tr,label_tr = append_time_dim(gtr, Ztr,time_stamps=t)\n",
    "                dat_te,label_te = append_time_dim(gte, Zte,time_stamps=t)\n",
    "\n",
    "                Label_te[mov].append(label_te)\n",
    "                Label_tr[mov].append(label_tr)\n",
    "\n",
    "                clf, optimizer = get_model(USED_MODEL, x=dat_tr, y=label_tr)\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                scaler.fit(dat_tr)\n",
    "                dat_tr = scaler.transform(dat_tr)\n",
    "                dat_te = scaler.transform(dat_te)\n",
    "\n",
    "\n",
    "                clf.fit(dat_tr, label_tr)\n",
    "                Ypre_te[mov].append(clf.predict(dat_te))\n",
    "                Ypre_tr[mov].append(clf.predict(dat_tr))\n",
    "                # in the sklearn implementation r2 can be negative. We set negatives r2 to zero\n",
    "                r2_te = r2_score(label_te, clf.predict(dat_te))\n",
    "                if r2_te < 0: r2_te = 0\n",
    "                score_te[mov].append(r2_te)\n",
    "                r2_tr = r2_score(label_tr,clf.predict(dat_tr))\n",
    "                if r2_tr < 0: r2_tr = 0\n",
    "\n",
    "                score_tr[mov].append(r2_tr)\n",
    "\n",
    "                if USED_MODEL > 1:\n",
    "                    Coef[mov].append(clf.beta_)\n",
    "                else:\n",
    "                    Coef[mov].append(clf.coef_)\n",
    "                hyperparams[mov].append(optimizer['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-anchor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-minute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
