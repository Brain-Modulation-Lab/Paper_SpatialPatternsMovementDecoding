{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "labeled-action",
   "metadata": {},
   "source": [
    "## ECoG+STN-LFP analysis: demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quarterly-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import mne\n",
    "from mne.decoding import SPoC\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "import pickle \n",
    "import sys\n",
    "# from Utilities folder\n",
    "sys.path.insert(1, './Utilities/icn_m1')\n",
    "import os\n",
    "sys.path.insert(1, './Utilities/')\n",
    "from FilterBank import FilterBank\n",
    "from ML_models import get_model\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define settings\n",
    "# change them accordinly\n",
    "settings = {}\n",
    "settings['data_path'] = \"C:/Users/Pilin/Dropbox (Brain Modulation Lab)/Experiments/CRCNS/Data/Epoched/\"\n",
    "settings['num_patients'] = ['000'] # for this example we only use one subject\n",
    "# subfolders indicates the session in this dataset\n",
    "settings['subfolders']=[['ses-right']]  # this subject only has one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some experiments and model parameters\n",
    "laterality = [\"CON\", \"IPS\"]\n",
    "signal = [\"STN\", \"ECOG\"]\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=False)\n",
    "spoc = SPoC(n_components=1, log=True, reg='oas', transform_into ='average_power', rank='full')\n",
    "USED_MODEL = 3 # 3 == GLM with alpha 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-pitch",
   "metadata": {},
   "source": [
    "### Load the data from both modalities.\n",
    "This data was already pre-processed, following these steps:\n",
    "1. Epochs of 100 ms were extracted.\n",
    "2. Band-passed filtered epoched data at 8 frequency bands ([4, 8], [8, 12], [13, 20], [20, 35], [13, 35], [60, 80], [90, 200], [60, 200])\n",
    "3. The target variable was downsampled accordinly to the 100 ms epoch lenght.\n",
    "\n",
    "If you want to run this code with your own data, please be sure of arranging your data in a 4d array as follows:\n",
    "(epochs, channels, samples, frequency bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare saving variable\n",
    "Ypre_tr = OrderedDict()\n",
    "score_tr = OrderedDict()\n",
    "Ypre_te = OrderedDict()\n",
    "score_te = OrderedDict()\n",
    "Patterns_ecog = OrderedDict()\n",
    "Filters_ecog = OrderedDict()\n",
    "Patterns_stn = OrderedDict()\n",
    "Filters_stn = OrderedDict()\n",
    "Coef = OrderedDict()\n",
    "hyperparams = OrderedDict()\n",
    "Label_tr = OrderedDict()\n",
    "Label_te = OrderedDict()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "s = 0 # when working with all subjects, this is a for\n",
    "subfolders=settings[\"subfolders\"][s]\n",
    "ss = 0 # when working with all subjects, this is a for, since there are subjects which have more than one session.\n",
    "X_ECOG = [] # to append data\n",
    "X_STN =[] \n",
    "Y_con = []\n",
    "Y_ips = []\n",
    "list_of_files_ecog = os.listdir(settings['data_path']+'ECOG') # list of files in the current directory\n",
    "list_of_files_stn = os.listdir(settings['data_path']+'STN') \n",
    "\n",
    "file_name_ = 'ECOG_epochs_sub_' + settings['num_patients'][s] + '_sess_'+subfolders[ss][4:]\n",
    "\n",
    "file_ecog = [each_file for each_file in list_of_files_ecog if each_file.startswith(file_name_)]\n",
    "file_name_='STN_epochs_sub_' + settings['num_patients'][s] + '_sess_'+subfolders[ss][4:]\n",
    "\n",
    "# only load data from runs in which both modali\n",
    "file_stn= [each_file for each_file in list_of_files_stn if each_file.startswith(file_name_)]\n",
    "idx_file = [f for f in file_stn if list(set() & set(file_ecog))]\n",
    "matching_stn = [f for f in file_stn if any(f[4:] in xs for xs in file_ecog)]\n",
    "matching_ecog = [f for f in file_ecog if any(f[4:] in xs for xs in file_stn)]\n",
    "\n",
    "if len(matching_ecog) != len(matching_stn):\n",
    "    raise('Error loading data')\n",
    "\n",
    "for e in range(len(matching_ecog)):\n",
    "    with open(settings['data_path'] +'ECOG/' + matching_ecog[e], 'rb') as handle:\n",
    "        sub_ = pickle.load(handle)    \n",
    "        data = sub_['epochs']\n",
    "        X_ECOG.append(data)\n",
    "        label_ips = sub_['label_ips']\n",
    "        label_con = sub_['label_con']\n",
    "        Y_con.append(label_con)\n",
    "        Y_ips.append(label_ips)\n",
    "    with open(settings['data_path'] +'STN/' + matching_stn[e], 'rb') as handle:\n",
    "        sub_ = pickle.load(handle)\n",
    "        data = sub_['epochs']\n",
    "        X_STN.append(data)           \n",
    "\n",
    "X_ECOG = np.concatenate(X_ECOG, axis=0)\n",
    "X_STN = np.concatenate(X_STN, axis=0)\n",
    "Y_con = np.concatenate(Y_con, axis=0)\n",
    "Y_ips = np.concatenate(Y_ips, axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, mov in enumerate(laterality):\n",
    "    print(\"training %s\" %mov)\n",
    "    score_tr[mov] = []\n",
    "    score_te[mov] = []\n",
    "    Ypre_tr[mov] = []\n",
    "    Ypre_te[mov] = []\n",
    "    Label_tr[mov] = []\n",
    "    Label_te[mov] = []\n",
    "    Patterns_ecog[mov] = []\n",
    "    Filters_ecog[mov] = []\n",
    "    Patterns_stn[mov] = []\n",
    "    Filters_stn[mov] = []\n",
    "    Coef[mov] = []\n",
    "    hyperparams[mov] = []\n",
    "    if l==0:\n",
    "        label=Y_con\n",
    "    else:\n",
    "        label=Y_ips\n",
    "\n",
    "    features_ecog=FilterBank(estimator=spoc)\n",
    "    features_stn=FilterBank(estimator=spoc)\n",
    "\n",
    "    X_ECOG=X_ECOG.astype('float64')\n",
    "    X_STN=X_STN.astype('float64')\n",
    "\n",
    "    gtr=[]\n",
    "    gte=[]\n",
    "    for train_index, test_index in cv.split(label):\n",
    "        Ztr, Zte=label[train_index], label[test_index]\n",
    "        Xtr_ecog, Xte_ecog=X_ECOG[train_index], X_ECOG[test_index]\n",
    "        Xtr_stn, Xte_stn=X_STN[train_index], X_STN[test_index]\n",
    "        # features are learned from each modality and then concatenated\n",
    "        Gtr_ecog_cspoc, Gtr_stn_cspoc = features_ecog.fit_transform(Xtr_ecog, Ztr), features_stn.fit_transform(Xtr_stn, Ztr)\n",
    "        Gte_ecog_cspoc, Gte_stn_cspoc = features_ecog.transform(Xte_ecog), features_stn.transform(Xte_stn)\n",
    "\n",
    "        dat_tr=np.hstack((Gtr_ecog_cspoc,Gtr_stn_cspoc))\n",
    "        dat_te=np.hstack((Gte_ecog_cspoc,Gte_stn_cspoc))\n",
    "\n",
    "        Label_te[mov].append(Zte)\n",
    "        Label_tr[mov].append(Ztr)\n",
    "        \n",
    "        # get the model\n",
    "        clf, optimizer = get_model(USED_MODEL, x=dat_tr, y=Ztr)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(dat_tr)\n",
    "        dat_tr = scaler.transform(dat_tr)\n",
    "        dat_te = scaler.transform(dat_te)\n",
    "        \n",
    "        # fit the model\n",
    "        clf.fit(dat_tr, Ztr)\n",
    "        Ypre_te[mov].append(clf.predict(dat_te))\n",
    "        Ypre_tr[mov].append(clf.predict(dat_tr))\n",
    "        \n",
    "        # predict\n",
    "        r2_te = r2_score(Zte, clf.predict(dat_te))\n",
    "        if r2_te < 0: r2_te = 0\n",
    "        score_te[mov].append(r2_te)\n",
    "        r2_tr = r2_score(Ztr,clf.predict(dat_tr))\n",
    "        if r2_tr < 0: r2_tr = 0\n",
    "        score_tr[mov].append(r2_tr)\n",
    "        \n",
    "        # save model info\n",
    "        Filters_ecog[mov].append(features_ecog.filters)\n",
    "        Patterns_ecog[mov].append(features_ecog.patterns)\n",
    "\n",
    "        Filters_stn[mov].append(features_stn.filters)\n",
    "        Patterns_stn[mov].append(features_stn.patterns)\n",
    "\n",
    "        if USED_MODEL > 1:\n",
    "            Coef[mov].append(clf.beta_)\n",
    "        else:\n",
    "            Coef[mov].append(clf.coef_)\n",
    "\n",
    "        hyperparams[mov].append(optimizer['params'])\n",
    "        del Xtr_ecog, Xte_ecog, Xtr_stn, Xte_stn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
